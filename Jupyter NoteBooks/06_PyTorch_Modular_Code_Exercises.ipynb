{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 06. PyTorch Going Modular Exercises\n",
        "\n",
        "Welcome to the 05. PyTorch Going Modular exercise template notebook.\n",
        "\n",
        "There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n",
        "\n",
        "> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.\n",
        "\n",
        "## Resources and solutions\n",
        "\n",
        "* These exercises/solutions are based on [section 05. PyTorch Going Modular](https://www.learnpytorch.io/05_pytorch_going_modular/) of the Learn PyTorch for Deep Learning course by Zero to Mastery.\n",
        "\n",
        "**Solutions:**\n",
        "\n",
        "Try to complete the code below *before* looking at these.\n",
        "\n",
        "* See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/ijgFhMK3pp4).\n",
        "* See an example [solutions notebook for these exercises on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/05_pytorch_going_modular_exercise_solutions.ipynb)."
      ],
      "metadata": {
        "id": "zNqPNlYylluR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Turn the code to get the data (from section 1. Get Data) into a Python script, such as `get_data.py`.\n",
        "\n",
        "* When you run the script using `python get_data.py` it should check if the data already exists and skip downloading if it does.\n",
        "* If the data download is successful, you should be able to access the `pizza_steak_sushi` images from the `data` directory."
      ],
      "metadata": {
        "id": "bicbWSrPmfTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "%%writefile get_data.py\n",
        "\"\"\"\n",
        "File downloads, unzips, and sets up the model directories used for training a image classification model\n",
        "\"\"\"\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "data_path = Path('data/')\n",
        "image_path = data_path / 'pizza_steak_sushi'\n",
        "\n",
        "# Check/ Create data folder\n",
        "if image_path.is_dir():\n",
        "  print(f'Directory {image_path} exists already')\n",
        "else:\n",
        "  print(f'Making directory {image_path}....')\n",
        "  image_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Download and unzip\n",
        "with open(str(image_path)+'.zip', 'wb' ) as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(f'Downloading zip file at {str(image_path)+'.zip'}')\n",
        "  print()\n",
        "  f.write(request.content)\n",
        "\n",
        "with zipfile.ZipFile(str(image_path)+'.zip', 'r') as zip_ref:\n",
        "  print(f'Unzipping image folder {str(image_path)+'.zip'}')\n",
        "  zip_ref.extractall(image_path)\n",
        "\n",
        "os.remove(str(image_path)+'.zip')"
      ],
      "metadata": {
        "id": "r0BCn1XIYZ8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9d8bb4-f414-43e6-98ea-145276b6eb23"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing get_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example running of get_data.py\n",
        "!python get_data.py"
      ],
      "metadata": {
        "id": "_LrUOIC-YOP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a7ec14-a373-4cae-dc0a-97891e55d2f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making directory data/pizza_steak_sushi....\n",
            "Downloading zip file at data/pizza_steak_sushi.zip\n",
            "\n",
            "Unzipping image folder data/pizza_steak_sushi.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Use [Python's `argparse` module](https://docs.python.org/3/library/argparse.html) to be able to send the `train.py` custom hyperparameter values for training procedures.\n",
        "* Add an argument flag for using a different:\n",
        "  * Training/testing directory\n",
        "  * Learning rate\n",
        "  * Batch size\n",
        "  * Number of epochs to train for\n",
        "  * Number of hidden units in the TinyVGG model\n",
        "    * Keep the default values for each of the above arguments as what they already are (as in notebook 05).\n",
        "* For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs: `python train.py --learning_rate 0.003 batch_size 64 num_epochs 20`.\n",
        "* **Note:** Since `train.py` leverages the other scripts we created in section 05, such as, `model_builder.py`, `utils.py` and `engine.py`, you'll have to make sure they're available to use too. You can find these in the [`going_modular` folder on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular/going_modular)."
      ],
      "metadata": {
        "id": "zjyn7LU3mvkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "import os\n",
        "os.makedirs('going_modular', exist_ok=True)"
      ],
      "metadata": {
        "id": "5kqsvddgIYNf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoader's for image classification data.\n",
        "\"\"\"\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "num_workers = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int = num_workers\n",
        "):\n",
        "  \"\"\"\n",
        "  Creates training and testing DataLoaders.\n",
        "  Takes in a training and testing directory path and turns them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
        "\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader\n",
        "\n",
        "  Returns:\n",
        "  A tuple of (train_dataloader, test_dataloader, class_names).\n",
        "  Where class_names is a list of the target classes.\n",
        "\n",
        "  Example usage:\n",
        "    train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=path/to/train_dir, test_dir=path/to/test_dir, transform=some_transform, batch_size=32, num_workers=4)\n",
        "  \"\"\"\n",
        "\n",
        "  print('Creating Datasets........')\n",
        "  train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "  test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "  print(f'Train and Test datasets created')\n",
        "\n",
        "  print('Creating DataLoaders........')\n",
        "  train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "  test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True)\n",
        "  print(f'Train and Test DataLoaders created')\n",
        "\n",
        "  class_names = train_dataset.classes\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkZjjvqyHj92",
        "outputId": "b115e75d-a4b5-4cf4-90aa-d78cdd71b0d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\"\"\"\n",
        "Contains PyTorch model code to instantiate a TinyVGG model,\n",
        "from the CNN explainer website\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"Creates a TinyVGG architecture.\n",
        "\n",
        "  Replicates the TinyVGG acrchitecture from the CNN explainer website in Pytorch.\n",
        "  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "  Args:\n",
        "    input_shape: An integer indicating number of input channels,\n",
        "    hidden_units: An integer indicating number of hidden units between layers,\n",
        "    output_shape: An integer indicating number of outptu units\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units:int, output_shape:int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        # input_featuer len comes form hidden units being compressed\n",
        "        nn.Linear(in_features=hidden_units*13*13, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tznh5D8KIKw-",
        "outputId": "b4cc8696-c9cb-43cc-daf0-b3bff53253be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/engine.py\n",
        "\"\"\"\n",
        "Contains functions for training and testing PyTorch model.\n",
        "\"\"\"\n",
        "from typing import Dict, List, Tuple\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\" Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  Truns a target PyTorch model to training mode and then runs through all the required\n",
        "  training steps (forward pass, loss calculation, optimizer step).\n",
        "\n",
        "  Args:\n",
        "    mode: A PyTorch model to be trained.\n",
        "    dataLoader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorcch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    (0.112, 0.8743)\n",
        " \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  train_loss = train_acc = 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  train_loss = train_loss/ len(dataloader)\n",
        "  train_acc = train_acc/ len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\" Tests a PyTorch model for a single epoch.\n",
        "\n",
        "  Truns a target PyTorch model to eval mode and then runs forward pass.\n",
        "\n",
        "  Args:\n",
        "    mode: A PyTorch model to be trained.\n",
        "    dataLoader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    device: A target device to compute on (e.g. 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    (0.112, 0.8743)\n",
        " \"\"\"\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = test_acc = 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred_logits = model(X)\n",
        "      loss = loss_fn(test_pred_logits, y)\n",
        "      test_loss += loss.item()\n",
        "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model: torch.nn.Module, train_dataloader: torch.utils.data.DataLoader, test_dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device, epochs: int) -> Dict[str, List[float]]:\n",
        "  \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "  Passes a target PyTorch models through train_step() and test_step()\n",
        "  functions for a number of epochs, training and testing the model\n",
        "  in the same epoch loop.\n",
        "\n",
        "  Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "                 {train_loss: [2.0616, 1.0537],\n",
        "                  train_acc: [0.3945, 0.3945],\n",
        "                  test_loss: [1.2641, 1.5706],\n",
        "                  test_acc: [0.3400, 0.2973]}\n",
        "  \"\"\"\n",
        "  results = {'train_loss': [],\n",
        "             'train_acc': [],\n",
        "             'test_loss': [],\n",
        "             'test_acc': []\n",
        "             }\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model, dataloader=train_dataloader, loss_fn=loss_fn, device=device, optimizer=optimizer)\n",
        "    test_loss, test_acc = test_step(model=model, loss_fn=loss_fn, dataloader=test_dataloader, device=device)\n",
        "\n",
        "    print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "      )\n",
        "\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['test_acc'].append(test_acc)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcwoD6DJIclN",
        "outputId": "03115db9-6abb-48c8-cc42-75464e375859"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/utils.py\n",
        "\"\"\"\n",
        "Contains function to save the PyTorch model\n",
        "\"\"\"\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model:torch.nn.Module, target_dir:str, model_name:str):\n",
        "  \"\"\" Saves a PyTorch model to a target directory.\n",
        "\n",
        "  Args:\n",
        "    model: A target PyTorch model to save.\n",
        "    target_dir: A directory for saving the model to.\n",
        "    model_name: A filename for the saved model. Should Include either \".pth' or \".pt\"\n",
        "\n",
        "  Example usage:\n",
        "    save_model(model=model_0,\n",
        "                target_dir=\"models\",\n",
        "                model_name=\"05_going_modular_tingvgg_model.pth\")\n",
        "  \"\"\"\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  # Create model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith('.pt'), 'model_name should end with .pth or .pt'\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(), f=model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ue4ctPIgCn",
        "outputId": "25cbc8a3-17d4-4252-efa8-0576a104b81b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "%%writefile going_modular/train.py\n",
        "\"\"\"\n",
        "Trains a PyTorch image classification model using device-agnostic code.\n",
        "\n",
        "Args:\n",
        "    train: Training directory\n",
        "    test: Testing directory\n",
        "    learning_rate: Learning rate\n",
        "    batch_size: Batch size\n",
        "    num_epochs: Number of epochs to train for\n",
        "    hidden_units: Number of hidden units in the TinyVGG model\n",
        "\"\"\"\n",
        "import torch\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import data_setup\n",
        "import utils\n",
        "import engine\n",
        "import model_builder\n",
        "from timeit import default_timer as timer\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Setup Hyper parameters\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "batch_size = 32\n",
        "hidden_units = 10\n",
        "input_shape = 3\n",
        "\n",
        "\n",
        "# Setup directories\n",
        "train_dir = 'data/pizza_steak_sushi/train'\n",
        "test_dir = 'data/pizza_steak_sushi/test'\n",
        "\n",
        "parser.add_argument('-tr', '--train', default=train_dir, help='Training directory')\n",
        "parser.add_argument('-te', '--test', default=test_dir, help='Testing directory')\n",
        "parser.add_argument('-lr', '--learning_rate', type=float, default=learning_rate, help='Learning rate')\n",
        "parser.add_argument('-b', '--batch_size', type=int, default=batch_size, help='Batch size')\n",
        "parser.add_argument('-e', '--num_epochs', type=int, default=num_epochs, help='Number of epochs to train for')\n",
        "parser.add_argument('-hi', '--hidden_units', type=int, default=hidden_units, help='Number of hidden units in the TinyVGG model')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "train_dir = args.train\n",
        "test_dir = args.test\n",
        "learning_rate = args.learning_rate\n",
        "num_epochs = args.num_epochs\n",
        "batch_size = args.batch_size\n",
        "hidden_units = args.hidden_units\n",
        "\n",
        "# Device agnostice code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# transformmation\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                            test_dir=test_dir,\n",
        "                                                            transform=data_transform,\n",
        "                                                            batch_size=batch_size)\n",
        "\n",
        "# Create model\n",
        "model = model_builder.TinyVGG(input_shape=input_shape, hidden_units=hidden_units, output_shape=len(class_names))\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# Train model with engine\n",
        "engine.train(model=model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             device=device,\n",
        "             epochs=num_epochs\n",
        "             )\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
        "\n",
        "# Save the model using utils\n",
        "utils.save_model(model=model,\n",
        "                 model_name='06_going_modular_script_mode.pth',\n",
        "                 target_dir='models')"
      ],
      "metadata": {
        "id": "MKNDUp45YaW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1bdcb2-972b-453f-ea1f-7d943909255b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example running of train.py\n",
        "!python going_modular/train.py --num_epochs 5 --batch_size 128 --hidden_units 128 --learning_rate 0.0003"
      ],
      "metadata": {
        "id": "LzaJl39lC40N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a07641c-afbb-4aeb-ef9b-32cded173a9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Datasets........\n",
            "Train and Test datasets created\n",
            "Creating DataLoaders........\n",
            "Train and Test DataLoaders created\n",
            "\r  0% 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch: 1 | train_loss: 1.1031 | train_acc: 0.3137 | test_loss: 1.0937 | test_acc: 0.3333\n",
            " 20% 1/5 [00:30<02:02, 30.59s/it]Epoch: 2 | train_loss: 1.0942 | train_acc: 0.3434 | test_loss: 1.0972 | test_acc: 0.3467\n",
            " 40% 2/5 [01:05<01:38, 32.99s/it]Epoch: 3 | train_loss: 1.0791 | train_acc: 0.4221 | test_loss: 1.0757 | test_acc: 0.4000\n",
            " 60% 3/5 [01:41<01:08, 34.48s/it]Epoch: 4 | train_loss: 1.0478 | train_acc: 0.5049 | test_loss: 1.0443 | test_acc: 0.4667\n",
            " 80% 4/5 [02:13<00:33, 33.39s/it]Epoch: 5 | train_loss: 0.9915 | train_acc: 0.5310 | test_loss: 1.0381 | test_acc: 0.4533\n",
            "100% 5/5 [02:43<00:00, 32.79s/it]\n",
            "[INFO] Total training time: 163.940 seconds\n",
            "[INFO] Saving model to: models/06_going_modular_script_mode.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create a Python script to predict (such as `predict.py`) on a target image given a file path with a saved model.\n",
        "\n",
        "* For example, you should be able to run the command `python predict.py some_image.jpeg` and have a trained PyTorch model predict on the image and return its prediction.\n",
        "* To see example prediction code, check out the [predicting on a custom image section in notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function).\n",
        "* You may also have to write code to load in a trained model."
      ],
      "metadata": {
        "id": "P2g6EEYvm-46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "%%writefile going_modular/predict.py\n",
        "\"\"\"\n",
        "Contains code which loads pre-saved model and predicts on custom image\n",
        "\"\"\"\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import model_builder\n",
        "\n",
        "# Setup argument parser\n",
        "parser = argparse.ArgumentParser(description='Predict on custom image using trained model')\n",
        "\n",
        "parser.add_argument('-img', '--image', type=str, required=True, help='Path to image for prediction')\n",
        "parser.add_argument('-m', '--model_path', type=str, default='models/06_going_modular_script_mode.pth', help='Path to trained model')\n",
        "parser.add_argument('-d', '--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                    choices=['cuda', 'cpu'], help='Device to run inference on')\n",
        "parser.add_argument('-hu', '--hidden_units', type=int, default=10, help='Number of hidden units in model')\n",
        "parser.add_argument('-in', '--input_shape', type=int, default=3, help='Number of input channels')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Setup device\n",
        "device = args.device\n",
        "\n",
        "# Setup transformation\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "])\n",
        "\n",
        "def pred_and_plot_image(\n",
        "    model: torch.nn.Module,\n",
        "    image_path: str,\n",
        "    class_names: List[str] = None,\n",
        "    transform=None,\n",
        "    device: torch.device = device\n",
        "):\n",
        "    \"\"\"Makes a prediction for a given custom image once its path is known\"\"\"\n",
        "    # Load in the image and scale it\n",
        "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32) / 255\n",
        "\n",
        "    # Transform image\n",
        "    if transform is not None:\n",
        "        target_image_transformed = transform(target_image)\n",
        "    else:\n",
        "        target_image_transformed = target_image\n",
        "\n",
        "    # Add batch dimension\n",
        "    target = target_image_transformed.unsqueeze(0)\n",
        "\n",
        "    # Make sure both are on same device\n",
        "    target = target.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    # Pass image through the model\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        target_logits = model(target)\n",
        "        target_preds = target_logits.softmax(1).argmax(1)\n",
        "\n",
        "    # Display class name\n",
        "    if class_names is not None:\n",
        "        print(f\"Image belongs to: {class_names[target_preds]}\")\n",
        "    else:\n",
        "        print(f\"Predicted class: {target_preds}\")\n",
        "\n",
        "# Load the saved model state\n",
        "class_names = ['pizza', 'steak', 'sushi']\n",
        "saved_state = torch.load(args.model_path, map_location=device)\n",
        "\n",
        "# Try to infer hidden_units from the saved model if not specified\n",
        "if 'conv_block_1.0.weight' in saved_state:\n",
        "    inferred_hidden_units = saved_state['conv_block_1.0.weight'].shape[0]\n",
        "    print(f\"[INFO] Detected hidden_units={inferred_hidden_units} from saved model\")\n",
        "    hidden_units = inferred_hidden_units\n",
        "else:\n",
        "    hidden_units = args.hidden_units\n",
        "    print(f\"[INFO] Using hidden_units={hidden_units} from arguments\")\n",
        "\n",
        "# Create model with correct architecture\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape=args.input_shape,\n",
        "    hidden_units=hidden_units,\n",
        "    output_shape=len(class_names)\n",
        ")\n",
        "\n",
        "# Load saved weights\n",
        "model.load_state_dict(saved_state)\n",
        "print(f\"[INFO] Model loaded successfully from {args.model_path}\")\n",
        "\n",
        "# Make prediction\n",
        "pred_and_plot_image(\n",
        "    model=model,\n",
        "    image_path=args.image,\n",
        "    class_names=class_names,\n",
        "    transform=data_transform,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "HU7W6VZfYawP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842e394c-3f22-49f1-d92e-66a66c4fa13d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example running of predict.py\n",
        "!python going_modular/predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg"
      ],
      "metadata": {
        "id": "Zcvw9sitIn6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d68fbbc-03cc-478a-8cfd-d7bfc97dea1c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Detected hidden_units=128 from saved model\n",
            "[INFO] Model loaded successfully from models/06_going_modular_script_mode.pth\n",
            "Image belongs to: sushi\n"
          ]
        }
      ]
    }
  ]
}