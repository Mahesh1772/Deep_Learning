{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52hFRYX-tu2A"
      },
      "source": [
        "# 5.0 Going Modular: Part 1 (Cell Mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UmItGiTxsnf"
      },
      "source": [
        "This notebook is a cleaned up version of notebook5 TinyVGG trained on images of pizza, steak and sushi.\n",
        "\n",
        "This will be used as the base to make a script version of the same code to bring it modular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGl2M4F1yH5v"
      },
      "source": [
        "## 1. Get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTWKgelOyKcR"
      },
      "source": [
        "Download the same data from notebook 5, the `pizza_steak_sushi` dataset images of pizza, steak and sushi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAdmCV3PyY03",
        "outputId": "562d2e9e-3717-4c0d-a459-b8a03a896b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\\pizza_steak_sushi already exists!\n",
            "Downloading data.....\n",
            "Unzipping pizza, steak, sushi data ....\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / 'pizza_steak_sushi'\n",
        "\n",
        "# Make folder and download the data\n",
        "if image_path.is_dir():\n",
        "  print(f'{image_path} already exists!')\n",
        "else:\n",
        "  print(f'Did not find {image_path}, making directory')\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(data_path / 'pizza_steak_sushi.zip' , 'wb') as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading data.....\")\n",
        "  f.write(request.content)\n",
        "\n",
        "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
        "  print('Unzipping pizza, steak, sushi data ....')\n",
        "  zip_ref.extractall(image_path)\n",
        "\n",
        "os.remove(data_path / 'pizza_steak_sushi.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxxqpp730Et_",
        "outputId": "ef003848-f147-4e96-f353-a118b0046f08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(WindowsPath('data/pizza_steak_sushi/train'),\n",
              " WindowsPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'\n",
        "\n",
        "train_dir, test_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV96SjYb0Mgx"
      },
      "source": [
        "## 2. Create Datasets and DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvOJIiWQ0Qoh"
      },
      "source": [
        "Cast images into datasets, then into dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X72oUEN0VpQ",
        "outputId": "4d97dbb1-e0cb-4f2d-adc9-e00aad47b83a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data: \n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 225\n",
            "    Root location: data\\pizza_steak_sushi\\train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
            "               ToTensor()\n",
            "           )\n",
            "Test data\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 75\n",
            "    Root location: data\\pizza_steak_sushi\\test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Simple transform\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Using ImageFolder to create Datsets\n",
        "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
        "test_data = datasets.ImageFolder(root=test_dir, target_transform=None, transform=data_transform)\n",
        "\n",
        "print(f'Train data: \\n{train_data}\\nTest data\\n{test_data}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Aw0NnkK1iR6",
        "outputId": "2574ca72-50e9-4769-9a91-a03841e55a02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDqvFgEu1w0J",
        "outputId": "7b22e0e8-47bc-44b1-ad0e-e40d80504b1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pizza': 0, 'steak': 1, 'sushi': 2}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_FIpvPm10er",
        "outputId": "88a3e863-8446-4353-9301-c95e2f70746c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(225, 75)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1V2q7k-13Pa",
        "outputId": "f05904c1-b34b-4ff9-f43d-ca97336cb19e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x1f67a8b52b0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x1f67a8b5af0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=1, num_workers=1, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size=1, num_workers=1, shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_9Jwjyl3d8j",
        "outputId": "247973bf-1ed6-44c1-bc28-1167fa9303ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape: torch.Size([1, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
            "Label shape: torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f'Label shape: {label.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz2GgYNGJbc2"
      },
      "source": [
        "### 2.1 Create Datasets adn Dataloaders (script mode)\n",
        "\n",
        "Let us use the Jupyter magic command to create a `.py` file\n",
        "\n",
        "Save the code cell's contents to a file using the Jupyter magics `%%writefile filename`m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YxcQUJBCLGE9"
      },
      "outputs": [],
      "source": [
        "# Create a directory\n",
        "import os\n",
        "os.makedirs('going_modular')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXNvmQHpJ9Te",
        "outputId": "3039c1d0-9998-4338-9f43-5b5cbcdbdc06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing going_modular/data_setup.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoader's for image classification data.\n",
        "\"\"\"\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "num_workers = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int = num_workers\n",
        "):\n",
        "  \"\"\"\n",
        "  Creates training and testing DataLoaders.\n",
        "  Takes in a training and testing directory path and turns them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
        "\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader\n",
        "\n",
        "  Returns:\n",
        "  A tuple of (train_dataloader, test_dataloader, class_names).\n",
        "  Where class_names is a list of the target classes.\n",
        "\n",
        "  Example usage:\n",
        "    train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=path/to/train_dir, test_dir=path/to/test_dir, transform=some_transform, batch_size=32, num_workers=4)\n",
        "  \"\"\"\n",
        "\n",
        "  print('Creating Datasets........')\n",
        "  train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "  test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "  print(f'Train and Test datasets created')\n",
        "\n",
        "  print('Creating DataLoaders........')\n",
        "  train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "  test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True)\n",
        "  print(f'Train and Test DataLoaders created')\n",
        "\n",
        "  class_names = train_dataset.classes\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW6EqpCWnQ9K",
        "outputId": "15050ee2-1cdd-4e37-bda0-8e4039292aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Datasets........\n",
            "Train and Test datasets created\n",
            "Creating DataLoaders........\n",
            "Train and Test DataLoaders created\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "from going_modular import data_setup\n",
        "importlib.reload(data_setup)\n",
        "\n",
        "# Now use it\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=str(train_dir),\n",
        "    test_dir=str(test_dir),\n",
        "    batch_size=32,\n",
        "    transform=data_transform\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8kODUGT3x7T"
      },
      "source": [
        "## 3. Making a model (TinyVGG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GruxTrU131al"
      },
      "source": [
        "TinyVGG from the CNN Explainer Website with docstring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jdIY4Lbv37zC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"Creates a TinyVGG architecture.\n",
        "\n",
        "  Replicates the TinyVGG acrchitecture from the CNN explainer website in Pytorch.\n",
        "  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "  Args:\n",
        "    input_shape: An integer indicating number of input channels,\n",
        "    hidden_units: An integer indicating number of hidden units between layers,\n",
        "    output_shape: An integer indicating number of outptu units\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units:int, output_shape:int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        # input_featuer len comes form hidden units being compressed\n",
        "        nn.Linear(in_features=hidden_units*13*13, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoQt404d4DCd",
        "outputId": "37d928a4-eed3-491e-813e-baed954cfa44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(train_data.classes)).to(device)\n",
        "model_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iduTg1ors6uU"
      },
      "source": [
        "Dummy forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYI1giTT63Mu",
        "outputId": "2d7ff843-b384-46fe-db87-a261a6d894bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Single image shape: torch.Size([1, 3, 64, 64])\n",
            "\n",
            "Output logits: \n",
            "tensor([[ 0.0208, -0.0020,  0.0095]])\n",
            "\n",
            "Output prediction probabilities:\n",
            "tensor([[0.3371, 0.3295, 0.3333]])\n",
            "\n",
            "Output prediction label:\n",
            "tensor([0])\n",
            "\n",
            "Actual label:\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "img_batch, label_batch = next(iter(train_dataloader))\n",
        "\n",
        "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
        "print(f\"Single image shape: {img_single.shape}\\n\")\n",
        "\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  pred = model_0(img_single.to(device))\n",
        "\n",
        "print(f'Output logits: \\n{pred}\\n')\n",
        "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
        "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
        "print(f\"Actual label:\\n{label_single}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9n5SnnLrfDi"
      },
      "source": [
        "## 3.1 Making a model (TinyVGG) wiht a script (`model_builder.py`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDJtuzK5ropW",
        "outputId": "5f152460-328c-479c-b4d5-36c9e3513fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing going_modular/model_builder.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\"\"\"\n",
        "Contains PyTorch model code to instantiate a TinyVGG model,\n",
        "from the CNN explainer website\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"Creates a TinyVGG architecture.\n",
        "\n",
        "  Replicates the TinyVGG acrchitecture from the CNN explainer website in Pytorch.\n",
        "  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "  Args:\n",
        "    input_shape: An integer indicating number of input channels,\n",
        "    hidden_units: An integer indicating number of hidden units between layers,\n",
        "    output_shape: An integer indicating number of outptu units\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units:int, output_shape:int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        # input_featuer len comes form hidden units being compressed\n",
        "        nn.Linear(in_features=hidden_units*13*13, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdQgORK4sWib",
        "outputId": "d63f8b72-dc99-4a21-ef7f-9922eda39601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from going_modular import model_builder\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_1 = model_builder.TinyVGG(3,10,len(class_names)).to(device)\n",
        "model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWsEZF9ktAMC",
        "outputId": "01d30b1a-852b-43e9-a7e3-9aac47219890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Single image shape: torch.Size([1, 3, 64, 64])\n",
            "\n",
            "Output logits: \n",
            "tensor([[ 0.0208, -0.0020,  0.0095]])\n",
            "\n",
            "Output prediction probabilities:\n",
            "tensor([[0.3371, 0.3295, 0.3333]])\n",
            "\n",
            "Output prediction label:\n",
            "tensor([0])\n",
            "\n",
            "Actual label:\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "img_batch, label_batch = next(iter(train_dataloader))\n",
        "\n",
        "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
        "print(f\"Single image shape: {img_single.shape}\\n\")\n",
        "\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  pred = model_0(img_single.to(device))\n",
        "\n",
        "print(f'Output logits: \\n{pred}\\n')\n",
        "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
        "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
        "print(f\"Actual label:\\n{label_single}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM5b-6768MIg"
      },
      "source": [
        "## 4. Creating `train_step()` and `test_step()` functions and combine them for `train()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "drVdnHGh8g3v"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\" Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  Truns a target PyTorch model to training mode and then runs through all the required\n",
        "  training steps (forward pass, loss calculation, optimizer step).\n",
        "\n",
        "  Args:\n",
        "    mode: A PyTorch model to be trained.\n",
        "    dataLoader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorcch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    (0.112, 0.8743)\n",
        " \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  train_loss = train_acc = 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  train_loss = train_loss/ len(dataloader)\n",
        "  train_acc = train_acc/ len(dataloader)\n",
        "  return train_loss, train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "g_cv5TFQ-mvh"
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\" Tests a PyTorch model for a single epoch.\n",
        "\n",
        "  Truns a target PyTorch model to eval mode and then runs forward pass.\n",
        "\n",
        "  Args:\n",
        "    mode: A PyTorch model to be trained.\n",
        "    dataLoader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    device: A target device to compute on (e.g. 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    (0.112, 0.8743)\n",
        " \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  test_loss = test_acc = 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    test_pred_logits = model(X)\n",
        "    loss = loss_fn(test_pred_logits, y)\n",
        "    test_loss += loss.item()\n",
        "    test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "    test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iO4KGlpXAvJN"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model: torch.nn.Module, train_dataloader: torch.utils.data.DataLoader, test_dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device, epochs: int) -> Dict[str, List[float]]:\n",
        "  \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "  Passes a target PyTorch models through train_step() and test_step()\n",
        "  functions for a number of epochs, training and testing the model\n",
        "  in the same epoch loop.\n",
        "\n",
        "  Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "                 {train_loss: [2.0616, 1.0537],\n",
        "                  train_acc: [0.3945, 0.3945],\n",
        "                  test_loss: [1.2641, 1.5706],\n",
        "                  test_acc: [0.3400, 0.2973]}\n",
        "  \"\"\"\n",
        "  results = {'train_loss': [],\n",
        "             'train_acc': [],\n",
        "             'test_loss': [],\n",
        "             'test_acc': []\n",
        "             }\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model, dataloader=train_dataloader, loss_fn=loss_fn, device=device, optimizer=optimizer)\n",
        "    test_loss, test_acc = test_step(model=model, loss_fn=loss_fn, dataloader=test_dataloader, device=device)\n",
        "\n",
        "    print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "      )\n",
        "\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['test_acc'].append(test_acc)\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEiMOEnvwjgC"
      },
      "source": [
        "## 4.1 Training functions into a script (`engine.py`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTJWNqi-w9Gf",
        "outputId": "a7470c64-98f2-4b1c-eb17-e5523f01cbcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing going_modular/engine.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/engine.py\n",
        "\"\"\"\n",
        "Contains functions for training and testing PyTorch model.\n",
        "\"\"\"\n",
        "from typing import Dict, List, Tuple\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\" Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  Truns a target PyTorch model to training mode and then runs through all the required\n",
        "  training steps (forward pass, loss calculation, optimizer step).\n",
        "\n",
        "  Args:\n",
        "    mode: A PyTorch model to be trained.\n",
        "    dataLoader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorcch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    (0.112, 0.8743)\n",
        " \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  train_loss = train_acc = 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  train_loss = train_loss/ len(dataloader)\n",
        "  train_acc = train_acc/ len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\" Tests a PyTorch model for a single epoch.\n",
        "\n",
        "  Truns a target PyTorch model to eval mode and then runs forward pass.\n",
        "\n",
        "  Args:\n",
        "    mode: A PyTorch model to be trained.\n",
        "    dataLoader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    device: A target device to compute on (e.g. 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    (0.112, 0.8743)\n",
        " \"\"\"\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = test_acc = 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred_logits = model(X)\n",
        "      loss = loss_fn(test_pred_logits, y)\n",
        "      test_loss += loss.item()\n",
        "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model: torch.nn.Module, train_dataloader: torch.utils.data.DataLoader, test_dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device, epochs: int) -> Dict[str, List[float]]:\n",
        "  \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "  Passes a target PyTorch models through train_step() and test_step()\n",
        "  functions for a number of epochs, training and testing the model\n",
        "  in the same epoch loop.\n",
        "\n",
        "  Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "                 {train_loss: [2.0616, 1.0537],\n",
        "                  train_acc: [0.3945, 0.3945],\n",
        "                  test_loss: [1.2641, 1.5706],\n",
        "                  test_acc: [0.3400, 0.2973]}\n",
        "  \"\"\"\n",
        "  results = {'train_loss': [],\n",
        "             'train_acc': [],\n",
        "             'test_loss': [],\n",
        "             'test_acc': []\n",
        "             }\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model, dataloader=train_dataloader, loss_fn=loss_fn, device=device, optimizer=optimizer)\n",
        "    test_loss, test_acc = test_step(model=model, loss_fn=loss_fn, dataloader=test_dataloader, device=device)\n",
        "\n",
        "    print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "      )\n",
        "\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['test_acc'].append(test_acc)\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998,
          "referenced_widgets": [
            "de8ac9983e634daf99df2ca96111d8b6",
            "829689def01e4d3faf268826de108fe2",
            "67172d95ceb646cc8a6b7805d52bcf13",
            "9adff7bfaee048a38efb07bed2196e95",
            "4e17a914894449ce92b581303466f536",
            "48547c7805e74af5a0aea47b86b74722",
            "442812902407425da52c9e0efe76ff47",
            "ae1881e647ce4dcb8744d83503ad075f",
            "33a50349f4884aee954e925898871f2f",
            "2ee75adc2dc04e71a492a562e5670b1f",
            "e2a4df5d8caa4bbb9bd214b7d36158b3"
          ]
        },
        "id": "KwkFfbSIxoJP",
        "outputId": "6ac79851-694b-41c0-b940-c7ed0b80a696"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'loss_fn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoing_modular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m engine\n\u001b[0;32m      3\u001b[0m engine\u001b[38;5;241m.\u001b[39mtrain(train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m      4\u001b[0m              model\u001b[38;5;241m=\u001b[39mmodel_1,\n\u001b[0;32m      5\u001b[0m              test_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m----> 6\u001b[0m              loss_fn\u001b[38;5;241m=\u001b[39m\u001b[43mloss_fn\u001b[49m,\n\u001b[0;32m      7\u001b[0m              optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m      8\u001b[0m              device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m      9\u001b[0m              epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'loss_fn' is not defined"
          ]
        }
      ],
      "source": [
        "from going_modular import engine\n",
        "\n",
        "engine.train(train_dataloader=train_dataloader,\n",
        "             model=model_1,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             device=device,\n",
        "             epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idSyaBemCNRb"
      },
      "source": [
        "## 5. Creating a function to save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "t2Hr_0w2CQ0C"
      },
      "outputs": [],
      "source": [
        "def save_model(model:torch.nn.Module, target_dir:str, model_name:str):\n",
        "  \"\"\" Saves a PyTorch model to a target directory.\n",
        "\n",
        "  Args:\n",
        "    model: A target PyTorch model to save.\n",
        "    target_dir: A directory for saving the model to.\n",
        "    model_name: A filename for the saved model. Should Include either \".pth' or \".pt\"\n",
        "\n",
        "  Example usage:\n",
        "    save_model(model=model_0,\n",
        "                target_dir=\"models\",\n",
        "                model_name=\"05_going_modular_tingvgg_model.pth\")\n",
        "  \"\"\"\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  # Create model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith('.pt'), 'model_name should end with .pth or .pt'\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(), f=model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dJ5R2iYxwaP"
      },
      "source": [
        "## 5.1 File to save utility functions called `utility.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG1x0yJlx1J2",
        "outputId": "3858b3cc-ab58-4a06-c3f4-27d7fba2ff4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing going_modular/utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/utils.py\n",
        "\"\"\"\n",
        "Contains function to save the PyTorch model\n",
        "\"\"\"\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model:torch.nn.Module, target_dir:str, model_name:str):\n",
        "  \"\"\" Saves a PyTorch model to a target directory.\n",
        "\n",
        "  Args:\n",
        "    model: A target PyTorch model to save.\n",
        "    target_dir: A directory for saving the model to.\n",
        "    model_name: A filename for the saved model. Should Include either \".pth' or \".pt\"\n",
        "\n",
        "  Example usage:\n",
        "    save_model(model=model_0,\n",
        "                target_dir=\"models\",\n",
        "                model_name=\"05_going_modular_tingvgg_model.pth\")\n",
        "  \"\"\"\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  # Create model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith('.pt'), 'model_name should end with .pth or .pt'\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(), f=model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqmTBjFhDbKl"
      },
      "source": [
        "## 6. Train, evaluate and save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "ed78a49ab6114768bfd49b40397ed23a",
            "48e7ceff29d043199019cba2bbc55358",
            "915b0cc252da4546896147c024662cc9",
            "3723588e937e4d31879685412f00cfe1",
            "9069af4a57264fa3bb31db4a382ee8d3",
            "48cbc9996075437a92ab3bee531e8f58",
            "04bd34e0099c4008bb356a742fc94ff1",
            "43f77d21f9d84a308d39c2b2bffdb7ea",
            "3d535fec48274c7c850624a15989dcc4",
            "4d156bd2096740858c5d4d2eed160cd0",
            "7b4775329c9f4609b6d840b4a2b237cb"
          ]
        },
        "id": "PohTG8RTDf4E",
        "outputId": "348f0d2b-0cc0-4813-d00b-174f0269ef2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:29<04:24, 29.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 1.1063 | train_acc: 0.3047 | test_loss: 1.0983 | test_acc: 0.3011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [00:56<03:42, 27.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | train_loss: 1.0998 | train_acc: 0.3281 | test_loss: 1.0697 | test_acc: 0.5417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [01:22<03:09, 27.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | train_loss: 1.0869 | train_acc: 0.4883 | test_loss: 1.0808 | test_acc: 0.4924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [02:08<03:26, 34.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4 | train_loss: 1.0843 | train_acc: 0.4023 | test_loss: 1.0608 | test_acc: 0.5833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [02:37<02:43, 32.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5 | train_loss: 1.0662 | train_acc: 0.4141 | test_loss: 1.0656 | test_acc: 0.5644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [03:09<02:09, 32.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6 | train_loss: 1.0305 | train_acc: 0.4375 | test_loss: 1.0139 | test_acc: 0.5426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [03:42<01:37, 32.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7 | train_loss: 0.9848 | train_acc: 0.4219 | test_loss: 0.9320 | test_acc: 0.5938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [04:13<01:04, 32.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8 | train_loss: 0.9607 | train_acc: 0.5820 | test_loss: 1.0057 | test_acc: 0.4640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [04:44<00:31, 31.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9 | train_loss: 0.9260 | train_acc: 0.5938 | test_loss: 1.0732 | test_acc: 0.3324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [05:15<00:00, 31.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10 | train_loss: 1.0013 | train_acc: 0.4570 | test_loss: 1.0571 | test_acc: 0.4044\n",
            "[INFO] Total training time: 315.130 seconds\n",
            "[INFO] Saving model to: models\\05_going_modular_cell_mode_tinyvgg_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "model_0 = TinyVGG(\n",
        "    input_shape=3,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(train_data.classes)\n",
        ").to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader=train_dataloader,\n",
        "                        test_dataloader=test_dataloader,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS,\n",
        "                        device=device)\n",
        "\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
        "\n",
        "# Save the model\n",
        "save_model(model=model_0,\n",
        "           target_dir=\"models\",\n",
        "           model_name=\"05_going_modular_cell_mode_tinyvgg_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGRkuVWCH_GZ"
      },
      "source": [
        "## 6.1 Train, evaluate and save mode (script mode)  `train.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBSeA8XzY7g"
      },
      "source": [
        "The master script uses all the other scrpits that were made above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwx1n94Lzcyz",
        "outputId": "74407fd0-7314-4460-e2f4-cb80df554d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing going_modular/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/train.py\n",
        "\"\"\"\n",
        "Trains a PyTorch image classification model using device-agnostic code.\n",
        "\"\"\"\n",
        "import torch\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import data_setup\n",
        "import utils\n",
        "import engine\n",
        "import model_builder\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Setup Hyper parameters\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "batch_size = 32\n",
        "hidden_units = 10\n",
        "input_shape = 3\n",
        "\n",
        "\n",
        "# Setup directories\n",
        "train_dir = 'data/pizza_steak_sushi/train'\n",
        "test_dir = 'data/pizza_steak_sushi/test'\n",
        "\n",
        "# Device agnostice code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# transformmation\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                            test_dir=test_dir,\n",
        "                                                            transform=data_transform,\n",
        "                                                            batch_size=batch_size)\n",
        "\n",
        "# Create model\n",
        "model = model_builder.TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names))\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# Train model with engine\n",
        "engine.train(model=model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             device=device,\n",
        "             epochs=num_epochs\n",
        "             )\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
        "\n",
        "# Save the model using utils\n",
        "utils.save_model(model=model,\n",
        "                 model_name='06_going_modular_script_mode.pth',\n",
        "                 target_dir='models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51zrOOlQz20T",
        "outputId": "23930446-c589-4549-c138-461785434326"
      },
      "outputs": [],
      "source": [
        "!python going_modular/train.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04bd34e0099c4008bb356a742fc94ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ee75adc2dc04e71a492a562e5670b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a50349f4884aee954e925898871f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3723588e937e4d31879685412f00cfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d156bd2096740858c5d4d2eed160cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_7b4775329c9f4609b6d840b4a2b237cb",
            "value": " 10/10 [00:31&lt;00:00,  3.41s/it]"
          }
        },
        "3d535fec48274c7c850624a15989dcc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43f77d21f9d84a308d39c2b2bffdb7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442812902407425da52c9e0efe76ff47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48547c7805e74af5a0aea47b86b74722": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48cbc9996075437a92ab3bee531e8f58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e7ceff29d043199019cba2bbc55358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48cbc9996075437a92ab3bee531e8f58",
            "placeholder": "​",
            "style": "IPY_MODEL_04bd34e0099c4008bb356a742fc94ff1",
            "value": "100%"
          }
        },
        "4d156bd2096740858c5d4d2eed160cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e17a914894449ce92b581303466f536": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67172d95ceb646cc8a6b7805d52bcf13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae1881e647ce4dcb8744d83503ad075f",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33a50349f4884aee954e925898871f2f",
            "value": 10
          }
        },
        "7b4775329c9f4609b6d840b4a2b237cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "829689def01e4d3faf268826de108fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48547c7805e74af5a0aea47b86b74722",
            "placeholder": "​",
            "style": "IPY_MODEL_442812902407425da52c9e0efe76ff47",
            "value": "100%"
          }
        },
        "9069af4a57264fa3bb31db4a382ee8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "915b0cc252da4546896147c024662cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43f77d21f9d84a308d39c2b2bffdb7ea",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d535fec48274c7c850624a15989dcc4",
            "value": 10
          }
        },
        "9adff7bfaee048a38efb07bed2196e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee75adc2dc04e71a492a562e5670b1f",
            "placeholder": "​",
            "style": "IPY_MODEL_e2a4df5d8caa4bbb9bd214b7d36158b3",
            "value": " 10/10 [00:22&lt;00:00,  2.38s/it]"
          }
        },
        "ae1881e647ce4dcb8744d83503ad075f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8ac9983e634daf99df2ca96111d8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_829689def01e4d3faf268826de108fe2",
              "IPY_MODEL_67172d95ceb646cc8a6b7805d52bcf13",
              "IPY_MODEL_9adff7bfaee048a38efb07bed2196e95"
            ],
            "layout": "IPY_MODEL_4e17a914894449ce92b581303466f536"
          }
        },
        "e2a4df5d8caa4bbb9bd214b7d36158b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed78a49ab6114768bfd49b40397ed23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48e7ceff29d043199019cba2bbc55358",
              "IPY_MODEL_915b0cc252da4546896147c024662cc9",
              "IPY_MODEL_3723588e937e4d31879685412f00cfe1"
            ],
            "layout": "IPY_MODEL_9069af4a57264fa3bb31db4a382ee8d3"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
